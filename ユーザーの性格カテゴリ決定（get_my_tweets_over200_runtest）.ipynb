{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自分のuser_idを入力してください\n",
      ">> ks_mocchaso\n",
      "----------------------------------------------------\n",
      "['scipyのsparse強すぎて感動してる', 'RT : 【応募用ツイート】 Progate登録ユーザー数が50万人を突破しました\\U0001f929😭みなさん本当にありがとうございます。感謝を込めて「パーカー＆Tシャツが当たるTwitterキャンペーン」を実施します❤️応募は をフォローしRTするだけ！詳しくはこ…', '5〜6分経てばフリーズは直るけど、In [*]のままだ…', 'あー、特徴ベクトルファイルに保存して読み込んでみたらフリーズした  結局フリーズ問題は付いてくるのか…', '特徴ベクトルづくりだけでこんなに時間食うとは… このままだとクソみたいな発表しかできんぞ…', '19:00寝3:30起きをキメた(晩飯前に寝てたら寝過ぎただけ)', ' GPUほぼ必須ですもんね！ 学生には辛い…。', ' 意外とあるあるなんですね！ レアなケースを引き当てたのかと思いましたw', '最低限のノルマまでは達成できそうなのにコーディング進まん笑 先に抄録とスライドづくりに着手するか…', 'ログの出し過ぎでjupyter固まってPCまでフリーズしたから、ファイル分割してtqdmまで導入したのに、まだ止まる時ある😭', '21893粒のポップコーンを召喚しました！【 伝説のポップコーンマスター 】  ', '全40問をクリアしました！ 所要時間は【47.2秒】です。  ', 'はてなブログに投稿しました  Git LFSでpushできるようになった！ - mocchaso - もっちゃそ ', 'Twitter APIの登録思ったよりだるくて草', ' 何となく検索かけてみたら、出てきてビックリしました ', 'すげえ、TrelloってiOSアプリ版もあるのか…！', 'Git LFS導入できぬ', 'Windows8、MeCabは何とか入れられるけどNEOlogdインストールできねえんか 今後の課題に挙げようかな…笑', '卒研関係で貰ったデータに不備があってキレそう', 'Slack連携のテスト〜', 'RT : プログラミング学ぶ上で、1番大事なのが逆算です。  ・何ができるようになりたいのかを決める ・そのために何が必要なのかを逆算してリストアップする ・それが学べるWebサービス、書籍を選ぶ  逆算しないと、いつまでも「できそうなコンテンツ」ば…', 'RT : あと、最近は最新技術の論文をGoogle Scholarみて事例調べたり、Lightening TalkのSlideshareみて技術のキャッチアップして、自分でも実装して何かしら便利そうだったらアプリに取り入れたりしています。 https…', 'RT : ', 'RT : プログラミング独学者向けに、圧倒的に質の高い情報だけ発信するサイトを作りました！  第4弾はPythonを学習する人向けにチュートリアルをまとめました。お盆にプログラミングの勉強を始めたい！という方はぜひ！  …', 'RT : jupyter notebook使いの皆様へ。東大松尾研の人に教えてもらいました。 コーディングする前にこのおまじないをしてみてください。 感動します。 from IPython.core.display import display, HTML…', 'RT : こちらはどうでしょう  趣味として楽しむ論文読みのススメ - karaage. [からあげ] ', 'はてなブログに投稿しました  タイピング練習について - mocchaso - もっちゃそ ', ' おお、ありがとうございます！', ' あ、完走コメントは以下でお願いします！笑  回を追うごとにPythonの知識が少しずつ増えていき、楽しさも増していきました。 解くのに時間がかかるときでも、辛抱強く取り組めたのは良かったです。 この演習での経験を活… ', 'Python100本ノック、クリアー！！ ', 'ついに完走いたしましたー！！', 'Python100本ノック 97本目～101本目（96本目～100本目） - mocchaso - もっちゃそ ', '大学と某企業合同開催の開発コンテストの中継観てるけど、なかなかオモロい', 'Python100本ノック、あともう少し頑張るぞ…！💪', 'はてなブログに投稿しました  Python100本ノック 92本目～96本目（91本目～95本目） - mocchaso - もっちゃそ ', 'はてなブログに投稿しました  Python100本ノック 90本目～91本目（89本目～90本目） - mocchaso - もっちゃそ ', 'はてなブログに投稿しました  Python100本ノック 82本目〜89本目(81本目〜88本目) - mocchaso - もっちゃそ ', 'Python100本ノック 72本目～81本目（71本目～80本目） - mocchaso - もっちゃそ ', ' そんな事無いですよ笑 まだまだ精進いたします(^_^;)', ' はい、終わりが見えてきました…！ ここまでやってきて、力がついてる感じしてます。', ' お褒めいただき恐縮です😆 やるからには自分の力になるようなやり方でやろうと思った次第です！ やっと80本目まで出来ました…！', 'Python100本ノック 62本目～71本目（63本目～70本目） - mocchaso - もっちゃそ ', 'Python100本ノック 53本目～61本目 - mocchaso - もっちゃそ ', 'Python100本ノック 45本目～52本目 - mocchaso - もっちゃそ ', 'Python100本ノック 41本目～44本目 - mocchaso - もっちゃそ ', 'RT : ドラクエより分かりやすいw ', 'Python100本ノック 36本目～40本目 - mocchaso - もっちゃそ ', 'Python100本ノック 31本目～35本目 - mocchaso - もっちゃそ ', 'Python100本ノック 26本目～30本目 - mocchaso - もっちゃそ ', 'Python100本ノック 21本目～25本目 - mocchaso - もっちゃそ ', '勘弁してくれ…', '駅着く直前で電車止まったざけんな', ' 自分も後者ですねー。焦らず進めていきます！   メモみたいな感じで書いてたんですが、思わぬところで役立ったみたいで嬉しいです…！', ' おおお、渡辺さんからコメント頂けるなんて感激です…！  ありがとうございます！ 一気に進められないかもしれませんが、少しずつでも頑張ります💪', 'Python100本ノック 16本目～20本目 - mocchaso - もっちゃそ ', 'Python100本ノック 11本目～15本目  - mocchaso - もっちゃそ ', 'Python100本ノック 7本目～10本目 - mocchaso - もっちゃそ ', '論文の著者にメール出したら、きちんと返信してくれて凄く感動した…。', '就活、完全にDONE', '卒業研究のテーマの候補、1つ消えた…orz  …', '卒論に役立つかも… ', ' そういうことでしたか笑  休憩ゾーンのおかげで、より続けられそうです！', ' はい、頑張ります！ 段階的に難しくなるわけではないんですね。休憩ゾーンって感じでしょうか…？', ' こちらこそ、問題を作ってくださりありがとうございます！ まだ15問までしか解けてないので、頑張ります笑', '感情分析+対話コーパス形成 →ユーザーがシステムに質問を投げて、システムがそれを解決に導こうとする対話システム  果たしてこれを実現できるのか…？orz', '卒業研究でやること固めてる途中だけど、思いついた方針でちょくちょく壁にぶつかるなあ…。', 'はてなブログに投稿しました  mocchaso - もっちゃそ ', 'はてなブログの設定をいじってみた - mocchaso - もっちゃそ ', 'やりたいことメモ - mocchaso - もっちゃそ ', '初めての投稿～ - mocchaso - もっちゃそ ', '・PyQ  こんなサービスもあるのかー。一応メモ。 ', '・Aidemy(とりあえず無料コースだけ) ', '・Unityの勉強(チュートリアル試していじってみたり) ・Unity カードゲーム創りの続き ・Unity Kinectと連携させてるゲーム創りの続き ・ゼロからDeepを読む&コード動かす ・パターン認識の授業のコード動かす… ', '2018年5月24日（木） ', '・Python100本ノック  ・Progate  ・CheckiO  ・言語処理100本ノ… ', 'プログラミング関連をつぶやくためのアカウントを作ってみた。初ツイート！']\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python                                                                                                                                             \n",
    "# -*- coding:utf-8 -*-  \n",
    "import json\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from twitter import Twitter, OAuth\n",
    "from janome.tokenizer import Tokenizer\n",
    "import collections\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import sys, json, time, calendar\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#APIキーの設置\n",
    "CONSUMER_KEY =  'Ojj0Pxe8CQ0ClLvnP1OQnvbBT'\n",
    "CONSUMER_SECRET = 'UiAFp6A9AvSb3Q7tD3NY5nr8bmGIvCtnGyQzlhnHxHeyY5bJI8'\n",
    "ACCESS_TOKEN = '999656799220322304-YJRSS4O7VvsZRCt2rsjrD32uiDs1rIC'\n",
    "ACCESS_SECRET = 'BNEd1qWjZzuwdiwRUl2xglkqpCrnR9dwgcdJLQfkUuGsk'\n",
    "\n",
    "t = Twitter(auth=OAuth(\n",
    "    ACCESS_TOKEN,\n",
    "    ACCESS_SECRET,\n",
    "    CONSUMER_KEY,\n",
    "    CONSUMER_SECRET\n",
    "))\n",
    "    \n",
    "twitter = OAuth1Session(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET)\n",
    "url = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "userTweets = []\n",
    "\n",
    "def get_userstweets_again(screen_name, max_id):\n",
    "    max_id = max_id\n",
    "    count = 200 #一度のアクセスで何件取ってくるか\n",
    "    aTimeLine = t.statuses.user_timeline(screen_name = screen_name, count=count, max_id=max_id)\n",
    "    for tweet in aTimeLine:\n",
    "        userTweets.append(tweet['text'])\n",
    "\n",
    "def get_userstweets(screen_name):\n",
    "    number_of_tweets = 0\n",
    "    count = 200 #一度のアクセスで何件取ってくるか\n",
    "    aTimeLine = t.statuses.user_timeline(screen_name = screen_name, count=count)\n",
    "    for tweet in aTimeLine:\n",
    "        number_of_tweets += 1\n",
    "        userTweets.append(tweet['text'])\n",
    "        if number_of_tweets >= 200:\n",
    "            max_id = tweet[\"id\"]\n",
    "            print(max_id)\n",
    "            get_userstweets_again(screen_name, max_id)\n",
    "    return userTweets\n",
    "            \n",
    "            \n",
    "def get_shaped_tweets(tweets_list):\n",
    "    shaped_tweets = []\n",
    "    rm_replie = re.compile(r'@([A-Za-z0-9_]+)')\n",
    "    rm_url = re.compile(r'https?://t.co/([A-Za-z0-9_]+)')\n",
    "    rm_hashtag = re.compile(r'#(\\w+)')\n",
    "    for tweet in tweets_list:\n",
    "        shape = rm_replie.sub('', tweet)\n",
    "        shape = rm_url.sub('', shape)\n",
    "        shape = rm_hashtag.sub('', shape)\n",
    "        shape = shape.replace('&gt;', '>').replace('&lt;', '<').replace('&amp;', '&').replace('\\n', ' ')\n",
    "        shaped_tweets.append(shape)\n",
    "    return shaped_tweets\n",
    "\n",
    "\n",
    "\n",
    "#検索したい相手を指定 \n",
    "print(\"自分のuser_idを入力してください\")\n",
    "my_user_id = input('>> ')\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "tweets = get_userstweets(my_user_id)\n",
    "tweets = get_shaped_tweets(tweets)\n",
    "\n",
    "\n",
    "print(tweets)\n",
    "print(len(tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カテゴリの決定(本でやったのと同じ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#抽出したユーザーのツイートから性格を出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from watson_developer_cloud import PersonalityInsightsV3\n",
    "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
    "from collections import OrderedDict\n",
    "\n",
    "def get_personality(text):\n",
    "    \"\"\"\n",
    "    Personality Insightsを用いた性格分析の結果を取得する\n",
    "    参考サイト：http://tmngtm.hatenablog.com/entry/2016/10/14/203901\n",
    "    -> return responseで400コードが出てうまくいかず(後で分かったことだが、恐らくContent-Languageをenにしていた...)\n",
    "    -> 公式マニュアルを読み解いた\n",
    "    ※事前に、pip install --upgrade watson-developer-cloud\n",
    "    \"\"\"\n",
    "    api_version = \"2017-10-13\"\n",
    "    api_username = \"396677bb-f0d3-4650-9d16-9e479f9e1f78\"\n",
    "    api_password = \"CyJVefXvDdIA\"\n",
    "    api_url = \"https://gateway.watsonplatform.net/personality-insights/api\"\n",
    "    \n",
    "    personality_insights = PersonalityInsightsV3(\n",
    "        version = api_version,\n",
    "        username = api_username,\n",
    "        password = api_password,\n",
    "        url = api_url\n",
    "    )\n",
    "    \n",
    "    profile = personality_insights.profile(\n",
    "        content = text,\n",
    "        content_type = \"text/plain\",\n",
    "        accept = \"application/json\",\n",
    "        content_language = \"ja\",\n",
    "        accept_language = \"en\",\n",
    "        raw_scores = True,\n",
    "    )\n",
    "    \n",
    "    return profile\n",
    "\n",
    "def convert_dict_to_json(orig_dict, indent = 4):\n",
    "    \"\"\"\n",
    "    辞書からJSON形式に変換する\n",
    "    参考サイト：https://tmg0525.hatenadiary.jp/entry/2018/03/30/204448\n",
    "    \"\"\"\n",
    "    return json.dumps(orig_dict)\n",
    "\n",
    "def load_json_as_dict(json_name):\n",
    "    \"\"\"\n",
    "    JSON形式の文字列を辞書として読み込む\n",
    "    参考サイト：https://note.nkmk.me/python-json-load-dump/\n",
    "    \"\"\"\n",
    "    with open(\"./\" + json_name, \"r\") as json_file:\n",
    "        return json.load(json_file, object_pairs_hook = OrderedDict)\n",
    "\n",
    "def sort_personality(tweet_result):\n",
    "    \"\"\"\n",
    "    tweet_resultを性格の値で降順にソートし、リストとしてreturnする\n",
    "    returnされたリストをスライスすれば一部を取得できる\n",
    "    カテゴリ分けの時に使う\n",
    "    \"\"\"\n",
    "    return sorted(tweet_result.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished analyzing all(76) tweets.\n"
     ]
    }
   ],
   "source": [
    "## ユーザのツイートを性格APIで分析する\n",
    "\n",
    "tweets_joined = \" \".join(tweets) # 集めた複数のツイートを結合\n",
    "user_personality_dict = OrderedDict()\n",
    "\n",
    "tweet_personality_dict = get_personality(tweets_joined) # ツイートを結合したデータをAPIに入力\n",
    "# ツイートから分析した性格の名前\n",
    "personality_name = [big5[\"name\"] for big5 in tweet_personality_dict[\"personality\"]]\n",
    "# 性格の値。小数点第2位で四捨五入した後、decimal.Decimalからfloatに変換している。\n",
    "# 参考サイト(四捨五入)：https://note.nkmk.me/python-round-decimal-quantize/\n",
    "personality_percentile = [float(Decimal(str(big5[\"percentile\"])).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)) \\\n",
    "                          for big5 in tweet_personality_dict[\"personality\"]]\n",
    "\n",
    "# ユーザのツイートの分析結果\n",
    "all_tweets_big5 = OrderedDict(zip(personality_name, personality_percentile))\n",
    "\n",
    "# { my_user_id: { personality_name1: percentile1, personality2: percentile2, ... } }\n",
    "user_personality_dict[my_user_id] = all_tweets_big5\n",
    "print(\"finished analyzing all({}) tweets.\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_patterns = \n",
      "[{'Conscientiousness', 'Agreeableness'},\n",
      " {'Emotional range', 'Agreeableness'},\n",
      " {'Extraversion', 'Agreeableness'},\n",
      " {'Openness', 'Agreeableness'},\n",
      " {'Emotional range', 'Conscientiousness'},\n",
      " {'Extraversion', 'Conscientiousness'},\n",
      " {'Openness', 'Conscientiousness'},\n",
      " {'Emotional range', 'Extraversion'},\n",
      " {'Emotional range', 'Openness'},\n",
      " {'Openness', 'Extraversion'}]\n",
      "\n",
      "OrderedDict([('ks_mocchaso', {'Emotional range', 'Conscientiousness'})])\n"
     ]
    }
   ],
   "source": [
    "## 分析結果を基に、本のカテゴリ分けを行う。\n",
    "\n",
    "import pprint\n",
    "import itertools\n",
    "\n",
    "# Agreeableness: 協調性, Conscientiousness: 真面目さ, Emotional range: 精神的安定性, Extraversion: 外向性, Openness: 開放性\n",
    "# 参考サイト：https://note.nkmk.me/python-math-factorial-permutations-combinations/\n",
    "big5_list = [\"Agreeableness\", \"Conscientiousness\", \"Emotional range\", \"Extraversion\", \"Openness\"]\n",
    "\n",
    "# big5から2つの性格を選ぶ組み合わせを列挙する\n",
    "category_patterns = [set(pat) for pat in itertools.combinations(big5_list, 2)]\n",
    "\n",
    "# ユーザのツイートのカテゴリ分けを記録する辞書\n",
    "user_tweet_category_table = OrderedDict()\n",
    "\n",
    "# ユーザのツイートの分析結果を、値の大きい順にソートする\n",
    "sorted_result = sort_personality(user_personality_dict[my_user_id])\n",
    "\n",
    "# big5のうち大きい順から2番目までの値の性格名のみを取得し、その本のカテゴリとする(例：{Openness, Extraversion})\n",
    "# この時、複数の性格の順番を考慮させないために、setで用意する\n",
    "# 2つを組み合わせているため、1つだけの場合よりも幅広くカテゴリ分けできそう\n",
    "tweet_category = {big5_elm[0] for big5_elm in sorted_result[0:2]}\n",
    "user_tweet_category_table[my_user_id] = tweet_category\n",
    "\n",
    "print(\"category_patterns = \")\n",
    "pprint.pprint(category_patterns)\n",
    "print()\n",
    "pprint.pprint(user_tweet_category_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 条件分岐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#本のカテゴリと一致した場合その本をサジェストする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found a sugested book...\n"
     ]
    }
   ],
   "source": [
    "#こんな感じ\n",
    "import random\n",
    "\n",
    "user_personality = user_tweet_category_table[my_user_id]\n",
    "\n",
    "suggest_book = \"\"\n",
    "if user_personality == {'Openness', 'Extraversion'}:\n",
    "    candidates = ['chumonno_oi_ryoriten', 'hashire_merosu']\n",
    "    suggest_book = random.choice(candidates)\n",
    "    print(\"book: {} was suggested.\".format(suggest_book))\n",
    "elif user_personality == {'Openness', 'Emotional range'}: \n",
    "    suggest_book = 'bocchan'\n",
    "    print(\"book: {} was suggested.\".format(suggest_book))\n",
    "elif user_personality == {'Openness', 'Agreeableness'}:\n",
    "    candidates = ['kaijin_nijumenso', 'ningen_shikkaku']\n",
    "    suggest_book = random.choice(candidates)\n",
    "    print(\"book: {} was suggested.\".format(suggest_book))\n",
    "else:\n",
    "    print(\"not found a sugested book...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
