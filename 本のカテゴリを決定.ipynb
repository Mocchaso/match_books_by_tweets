{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 変数や関数の定義\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from watson_developer_cloud import PersonalityInsightsV3\n",
    "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 本の文章データ名\n",
    "books = [\"bocchan.txt\", \"chumonno_oi_ryoriten.txt\", \"hashire_merosu.txt\", \"kaijin_nijumenso.txt\", \"ningen_shikkaku.txt\"]\n",
    "# 抽出した本のストーリーを保存するフォルダ\n",
    "stored_path = Path(\"./extracted_bookdata\")\n",
    "# 全ての本の分析結果を保存するJSONファイルの名前\n",
    "analyzed_all_book_json_name = \"analyzed_all_book.json\"\n",
    "\n",
    "def get_personality(text):\n",
    "    \"\"\"\n",
    "    Personality Insightsを用いた性格分析の結果を取得する\n",
    "    参考サイト：http://tmngtm.hatenablog.com/entry/2016/10/14/203901\n",
    "    -> return responseで400コードが出てうまくいかず(後で分かったことだが、恐らくContent-Languageをenにしていた...)\n",
    "    -> 公式マニュアルを読み解いた\n",
    "    ※事前に、pip install --upgrade watson-developer-cloud\n",
    "    \"\"\"\n",
    "    api_version = \"2017-10-13\"\n",
    "    api_username = \"396677bb-f0d3-4650-9d16-9e479f9e1f78\"\n",
    "    api_password = \"CyJVefXvDdIA\"\n",
    "    api_url = \"https://gateway.watsonplatform.net/personality-insights/api\"\n",
    "    \n",
    "    personality_insights = PersonalityInsightsV3(\n",
    "        version = api_version,\n",
    "        username = api_username,\n",
    "        password = api_password,\n",
    "        url = api_url\n",
    "    )\n",
    "    \n",
    "    profile = personality_insights.profile(\n",
    "        content = text,\n",
    "        content_type = \"text/plain\",\n",
    "        accept = \"application/json\",\n",
    "        content_language = \"ja\",\n",
    "        accept_language = \"en\",\n",
    "        raw_scores = True,\n",
    "    )\n",
    "    \n",
    "    return profile\n",
    "\n",
    "def get_personality_old(text):\n",
    "    \"\"\"\n",
    "    上記参考サイトのコード＋少々改変版。\n",
    "    Content-Languageをjaにしていればできてたっぽい。\n",
    "    \"\"\"\n",
    "    # endpoint url\n",
    "    api_url = \"https://gateway.watsonplatform.net/personality-insights/api/v2/profile\"\n",
    "    # username and password for this api\n",
    "    api_username = \""\n",
    "    api_password = \""\n",
    "    \n",
    "    # set query\n",
    "    query = {\n",
    "        \"include_raw\": \"false\",\n",
    "        \"header\": \"false\"\n",
    "    }\n",
    "    \n",
    "    # set header\n",
    "    headers = {\n",
    "        \"Content-Type\": \"text/plain\", # 入力テキストの形式。今回はstringのテキストを渡す設定。\n",
    "        \"Content-Language\": \"en\",     # 入力言語モードの指定。jaとすると日本語の入力を受け付ける。\n",
    "        \"Accept\": \"application/json\", # 応答ファイルの形式。今回はjson形式で受け取る。\n",
    "        \"Accept-Language\": \"en\",      # 処理言語モードの設定。jaとすると日本語として処理する。\n",
    "        \"include_raw\": \"false\"\n",
    "    }\n",
    "    \n",
    "    # set body\n",
    "    body = text\n",
    "    body = body.encode(\"utf-8\") # 参考サイトのコードに追記\n",
    "    \n",
    "    # post\n",
    "    response = requests.post(\n",
    "        api_url,\n",
    "        auth = HTTPBasicAuth(api_username, api_password),\n",
    "        params = query,\n",
    "        headers = headers,\n",
    "        data = body\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def convert_dict_to_json(orig_dict, indent = 4):\n",
    "    \"\"\"\n",
    "    辞書からJSON形式に変換する\n",
    "    参考サイト：https://tmg0525.hatenadiary.jp/entry/2018/03/30/204448\n",
    "    \"\"\"\n",
    "    return json.dumps(orig_dict)\n",
    "\n",
    "def load_json_as_dict(json_name):\n",
    "    \"\"\"\n",
    "    JSON形式の文字列を辞書として読み込む\n",
    "    参考サイト：https://note.nkmk.me/python-json-load-dump/\n",
    "    \"\"\"\n",
    "    with open(\"./\" + json_name, \"r\") as json_file:\n",
    "        return json.load(json_file, object_pairs_hook = OrderedDict)\n",
    "\n",
    "def sort_personality(a_book_result):\n",
    "    \"\"\"\n",
    "    a_book_resultを性格の値で降順にソートし、リストとしてreturnする\n",
    "    returnされたリストをスライスすれば一部を取得できる\n",
    "    本のカテゴリ分けの時に使う\n",
    "    \"\"\"\n",
    "    return sorted(a_book_result.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished analyzing bocchan.txt .\n",
      "finished analyzing chumonno_oi_ryoriten.txt .\n",
      "finished analyzing hashire_merosu.txt .\n",
      "finished analyzing kaijin_nijumenso.txt .\n",
      "finished analyzing ningen_shikkaku.txt .\n",
      "finished analyzing all(5) books.\n",
      "registered result of analysis with file: analyzed_all_book.json\n"
     ]
    }
   ],
   "source": [
    "## 本(今回は全5冊)の文章データをPersonality Insightsに入力して分析させる\n",
    "## その結果を、JSONファイルに変換して保存する\n",
    "## -> このセルを1回実行しておけば、ファイルを読み込むだけで本の分析結果を利用できる\n",
    "\n",
    "# 全ての本(今回は5冊)の分析結果を格納する\n",
    "# { book1: { personality_name1: percentile1, personality2: percentile2, ... } , ... , book5: { personality5: percentile5, ... } }\n",
    "# 後でJSONファイルとして保存するため、順序付き辞書を使う\n",
    "# 参考サイト：https://note.nkmk.me/python-collections-ordereddict/\n",
    "all_book_big5 = OrderedDict()\n",
    "\n",
    "for book in books:\n",
    "    book_path = Path(stored_path.name + \"/\" + book) # Path(Path(\"./extracted_bookdata\") / book) でもOK\n",
    "    # 入力となる本の文章データ\n",
    "    story = book_path.read_text(encoding=\"utf-8\")\n",
    "    # personality insightsに、本の文章データを1つずつ順番に分析させる\n",
    "    story_personality_dict = get_personality(story)\n",
    "    \n",
    "    # 本の性格\n",
    "    personality_name = [big5[\"name\"] for big5 in story_personality_dict[\"personality\"]]\n",
    "    # 性格の値。小数点第2位で四捨五入した後、decimal.Decimalからfloatに変換している。\n",
    "    # 参考サイト(四捨五入)：https://note.nkmk.me/python-round-decimal-quantize/\n",
    "    personality_percentile = [float(Decimal(str(big5[\"percentile\"])).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)) \\\n",
    "                              for big5 in story_personality_dict[\"personality\"]]\n",
    "    # 1冊の本の分析結果\n",
    "    a_book_big5 = OrderedDict(zip(personality_name, personality_percentile))\n",
    "    # 全体の分析結果の辞書に追加\n",
    "    all_book_big5[book] = a_book_big5\n",
    "    \n",
    "    print(\"finished analyzing {} .\".format(book))\n",
    "    # JSONとして出力したくなったらコメントアウト解除\n",
    "    # print(convert_dict_to_json(story_personality_dict, 4))\n",
    "\n",
    "print(\"finished analyzing all({}) books.\".format(len(books)))\n",
    "\n",
    "# 全ての本の分析結果をJSONファイルとして保存する\n",
    "# このノートブックをシャットダウンしたら、jsonファイルの内容を閲覧できるようになる(それまでは何故か内容が更新されていない)\n",
    "fw = open(analyzed_all_book_json_name, \"w\")\n",
    "json.dump(all_book_big5, fw, indent = 4)\n",
    "print(\"registered result of analysis with file: {}\".format(analyzed_all_book_json_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Agreeableness', 'Conscientiousness'},\n",
      " {'Emotional range', 'Agreeableness'},\n",
      " {'Extraversion', 'Agreeableness'},\n",
      " {'Openness', 'Agreeableness'},\n",
      " {'Emotional range', 'Conscientiousness'},\n",
      " {'Extraversion', 'Conscientiousness'},\n",
      " {'Openness', 'Conscientiousness'},\n",
      " {'Extraversion', 'Emotional range'},\n",
      " {'Openness', 'Emotional range'},\n",
      " {'Openness', 'Extraversion'}]\n",
      "OrderedDict([('bocchan.txt', {'Openness', 'Emotional range'}),\n",
      "             ('chumonno_oi_ryoriten.txt', {'Openness', 'Extraversion'}),\n",
      "             ('hashire_merosu.txt', {'Openness', 'Extraversion'}),\n",
      "             ('kaijin_nijumenso.txt', {'Openness', 'Agreeableness'}),\n",
      "             ('ningen_shikkaku.txt', {'Openness', 'Agreeableness'})])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## 分析結果を基に、本のカテゴリ分けを行う。\n",
    "\n",
    "import pprint\n",
    "import itertools\n",
    "\n",
    "# カテゴリの通し番号\n",
    "serial_numbers = [i + 1 for i in range(10)]\n",
    "\n",
    "# Agreeableness: 協調性, Conscientiousness: 真面目さ, Emotional range: 精神的安定性, Extraversion: 外向性, Openness: 開放性\n",
    "# 参考サイト：https://note.nkmk.me/python-math-factorial-permutations-combinations/\n",
    "big5_list = [\"Agreeableness\", \"Conscientiousness\", \"Emotional range\", \"Extraversion\", \"Openness\"]\n",
    "\n",
    "# big5から2つの性格を選ぶ組み合わせを列挙する\n",
    "# JSONファイルの内容に合わせて要素をsetに変換する(順番を考慮すると)\n",
    "category_patterns = [set(pat) for pat in itertools.combinations(big5_list, 2)]\n",
    "\n",
    "# 本ごとのカテゴリ分けを記録する辞書\n",
    "all_book_category_table = OrderedDict()\n",
    "\n",
    "for book in books:\n",
    "    # 本の分析結果のJSONファイルをそれぞれ読み込み、値の大きい順にソートする\n",
    "    loaded_all_book_big5 = load_json_as_dict(analyzed_all_book_json_name)[book]\n",
    "    sorted_result = sort_personality(loaded_all_book_big5)\n",
    "    \n",
    "    # big5のうち大きい順から2番目までの値の性格名のみを取得し、その本のカテゴリとする(例：{Openness, Extraversion})\n",
    "    # この時、複数の性格の順番を考慮させないために、setで用意する\n",
    "    # 2つを組み合わせているため、1つだけの場合よりも幅広くカテゴリ分けできそう\n",
    "    book_category = {big5_elm[0] for big5_elm in sorted_result[0:2]}\n",
    "    all_book_category_table[book] = book_category\n",
    "\n",
    "pprint.pprint(category_patterns)\n",
    "pprint.pprint(all_book_category_table)\n",
    "print(all_book_category_table[\"bocchan.txt\"] in category_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
